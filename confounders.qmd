---
title: "Confounders"
crossref:
  def-title: Rule
  def-prefix: Rule
---

```{r}
#| label: tikz-setup
#| include: false

if (Sys.info()["sysname"] == "Darwin") {
  # Necessary for using dvisvgm on macOS
  # See https://www.andrewheiss.com/blog/2021/08/27/tikz-knitr-html-svg-fun/
  Sys.setenv(LIBGS = "/opt/homebrew/opt/ghostscript/lib/libgs.dylib")
}

knitr::opts_template$set(
  tikz_settings = list(
    fig.ext = "svg",
    fig.align = "center",
    extra.preamble = c(
      "\\usepackage{libertine}",
      "\\usepackage{libertinust1math}",
      "\\usepackage{positioning}"
    ),
    engine.opts = list(dvisvgm.opts = "--no-fonts")
  )
)
```

```{ojs}
//| echo: false

d3 = require("d3@7")
dag = import(new URL("js/dag-utils.js", document.baseURI).href)
```

::::::::: {.column-screen-inset}

::::: {.grid .interactive}

:::: {.g-col-12 .g-col-md-4}

###### Relationships between nodes

```{ojs}
//| echo: false

viewof strength_zx = Inputs.range([0, 1], {
  value: 0.5, 
  step: 0.05, 
  label: html`<span class="node node-z">Z</span> → <span class="node node-x">X</span> strength`
})

viewof strength_zy = Inputs.range([0, 1], {
  value: 0.5, 
  step: 0.05, 
  label: html`<span class="node node-z">Z</span> → <span class="node node-y">Y</span> strength`
})

viewof strength_xy = Inputs.range([0, 1], {
  value: 0.7, 
  step: 0.05, 
  label: html`<span class="node node-x">X</span> → <span class="node node-y">Y</span> strength`
})
```

###### Adjustments

```{ojs}
//| echo: false

viewof adjust_z = Inputs.toggle({
  label: html`<span class="node node-z">Adjust for Z</span> (<em>block backdoor path</em>)`
})
```

```{ojs}
//| echo: false

// ----------------
// Status readout
// ----------------
{
  const pctPure = Math.round(y_pure_x / yMax * 100);
  const pctConf = Math.round(y_confounded / yMax * 100);
  const pctZ = Math.round(y_direct_z / yMax * 100);
  const pctOwn = Math.max(0, 100 - pctPure - pctConf - pctZ);

  return html`<div class="alert alert-secondary status-readout">
    <h5 class="alert-heading">What Y contains</h5>
    <table>
      <tr>
        <td><svg width="12" height="12"><rect width="12" height="12" fill="${dag.colorX}"/></svg></td>
        <td><span class="node node-x">X</span>'s direct influence on <span class="node node-y">Y</span></td>
        <td>${pctPure}%</td>
      </tr>
      <tr>
        <td><svg width="12" height="12">
          <defs>
            <pattern id="legend-hatch-conf" patternUnits="userSpaceOnUse"
              width="6" height="6" patternTransform="rotate(45)">
              <rect width="6" height="6" fill="${dag.colorZ}"/>
              <line x1="0" y1="0" x2="0" y2="6"
                stroke="${dag.colorX}" stroke-width="2.5"/>
            </pattern>
          </defs>
          <rect width="12" height="12" fill="url(#legend-hatch-conf)"/>
        </svg></td>
        <td><span class="node node-z">Z</span>'s influence on <span class="node node-y">Y</span> via <span class="node node-x">X</span></td>
        <td>${pctConf}%</td>
      </tr>
      <tr>
        <td><svg width="12" height="12"><rect width="12" height="12" fill="${dag.colorZ}"/></svg></td>
        <td><span class="node node-z">Z</span>'s direct influence on <span class="node node-y">Y</span></td>
        <td>${pctZ}%</td>
      </tr>
      <tr>
        <td><svg width="12" height="12"><rect width="12" height="12" fill="${dag.colorY}"/></svg></td>
        <td><span class="node node-y">Y</span>'s own variation</td>
        <td>${pctOwn}%</td>
      </tr>
      <tr class="summary ${adjust_z ? 'dimmed' : ''}">
        <td>
          <svg width="12" height="12"><rect width="12" height="12" fill="${dag.colorX}"/></svg>
          +
          <svg width="12" height="12">
            <rect width="12" height="12" fill="url(#legend-hatch-conf)"/>
          </svg>
        </td>
        <td>Apparent <span class="node node-x">X</span> → <span class="node node-y">Y</span> effect</td>
        <td>${pctPure + pctConf}%</td>
      </tr>
      <tr class="summary ${adjust_z ? '' : 'dimmed'}">
        <td>
          <svg width="12" height="12"><rect width="12" height="12" fill="${dag.colorX}"/></svg>
        </td>
        <td>Unconfounded <span class="node node-x">X</span> → <span class="node node-y">Y</span> effect</td>
        <td>${pctPure}%</td>
      </tr>
    </table>
  </div>`;
}
```

::::

:::: {.g-col-12 .g-col-md-8}

```{ojs}
//| echo: false

// Values for all the relationships
yMax = 150
baseVal = 50

x_from_z = adjust_z ? 0 : strength_zx * baseVal

y_pure_x = strength_xy * baseVal
y_confounded = adjust_z ? 0 : strength_xy * x_from_z
y_direct_z = adjust_z ? 0 : strength_zy * baseVal
```

```{ojs}
//| echo: false

// -----------------
// Interactive DAG
// -----------------
{
  const width = 600;
  const height = 250;
  const nodeRadius = 36;

  const nodes = {
    Z: { x: width / 2, y: 60, label: "Z" },
    X: { x: 130, y: 200, label: "X" },
    Y: { x: 470, y: 200, label: "Y" }
  };

  const svg = d3.create("svg")
    .attr("viewBox", `0 0 ${width} ${height}`)
    .attr("width", width)
    .attr("height", height)
    .style("max-width", "100%");

  const defs = svg.append("defs");

  dag.addArrowMarkers(defs);
  dag.addHatchPattern(
    defs, "hatch-confounded", dag.colorZ, dag.colorX, 45
  );
  dag.addCircleClip(
    defs, "x-clip", nodes.X.x, nodes.X.y, nodeRadius
  );
  dag.addCircleClip(
    defs, "y-clip", nodes.Y.x, nodes.Y.y, nodeRadius
  );

  // Arrows
  const edges = [
    {
      id: "zx", from: nodes.Z, to: nodes.X,
      strength: strength_zx, blocked: adjust_z
    },
    {
      id: "zy", from: nodes.Z, to: nodes.Y,
      strength: strength_zy, blocked: adjust_z
    },
    {
      id: "xy", from: nodes.X, to: nodes.Y,
      strength: strength_xy, blocked: false
    }
  ];

  for (const edge of edges) {
    dag.drawEdge(svg, edge, nodeRadius);
  }

  // Nodes
  // X: strength directly controls fill proportion
  dag.drawNode(svg, nodes.X.x, nodes.X.y, nodeRadius, "x-clip", {
    bottomUp: [],
    topDown: [
      { prop: strength_zx, fill: dag.colorZ }
    ]
  }, undefined, dag.colorX);

  // Y: blue base, incoming effects overlay
  dag.drawNode(svg, nodes.Y.x, nodes.Y.y, nodeRadius, "y-clip", {
    bottomUp: [
      { prop: Math.min(y_pure_x / yMax, 1), fill: dag.colorX },
      {
        prop: Math.min(y_confounded / yMax, 1),
        fill: "url(#hatch-confounded)"
      }
    ],
    topDown: [
      { prop: Math.min(y_direct_z / yMax, 1), fill: dag.colorZ }
    ]
  }, undefined, dag.colorY);

  dag.drawSolidNode(
    svg, nodes.Z.x, nodes.Z.y, nodeRadius, dag.colorZ
  );

  // Labels
  for (const n of Object.values(nodes)) {
    dag.drawLabel(svg, n.x, n.y, n.label);
  }

  return svg.node();
}
```

::::

:::::

:::::::::

## How to adjust

TODO

- stratify with binary confounder and find weighted average across levels?
- control for things
- ipw
- matching
- g-computation?


## Backdoor adjustment more formally

Let's say that we're interested in the causal effect of $X$ on $Y$, but we have a confounder $Z$ that opens a backdoor path $X \leftarrow Z \rightarrow Y$, creating a DAG that looks like this:

```{tikz opts.label="tikz_settings"}
#| label: fig-dag
#| fig-cap: 'DAG with a confounder'
#| echo: false
#| out-width: 30%

\begin{tikzpicture}[>={stealth}]
  \node (x) at (0,0) {X};
  \node (y) at (2,0) {Y};
  \node (z) at (1,1) {Z};
  \path[->] (z) edge (x);
  \path[->] (z) edge (y);
  \path[->] (x) edge (y);
\end{tikzpicture}
```

Our target estimand is $P(y \mid \operatorname{do}(x))$,[^caveat] or the distribution of $Y$ in a world where we intervene to set $X = x$. However, that $\operatorname{do}(\cdot)$ operator represents a hypothetical intervention where we can set $X = x$ directly, breaking its usual causes. In an experimental setting, that works fine—we can randomly assign people to get assigned to different values of $x$. But in observational data, we don't have control over treatment assignment and we cannot intervene.

[^caveat]: *Strictly* speaking, that's not actually true! $P(y \mid \operatorname{do}(x))$ is an interventional distribution, while causal effects or estimands are contrasts of that distribution, like $E[Y \mid \operatorname{do}(x = 1)] - E[Y \mid \operatorname{do}(x = 0)]$. But for the sake of simplicity, we'll pretend.

To get around this, we can use Judea Pearl's *do*-calculus to eliminate the $\operatorname{do}(x)$ from $P(y \mid \operatorname{do} (x))$ and estimate the causal effect of $X$ on $Y$ using observational, non-experimental data.

To get there, we need to look at the idea of modifying graphs and define the three rules of *do*-calculus. We can then use those tools to derive a $\operatorname{do}(\cdot)$-free formula for our main estimand.

### Graph surgery

*do*-calculus consists of three rules that let you remove causal interventions like $\operatorname{do}(\cdot)$ from causal estimands, allowing you to estimate causal effects from observational data.

Each rule works by checking if specific nodes are d-separated in one of two specially modified versions of the original DAG (see @fig-modified-dags). We essentially perform surgery on these modified DAGs to remove arrows into or out of target nodes. These modified DAGs use a special kind of notation:

- $G$: This is the original DAG; see @fig-dag-original
- $G_{\overline{X}}$: This is $G$, but with all arrows going *into* $X$ deleted; see @fig-dag-overbar
- $G_{\underline{X}}$: This is $G$, but with all arrows going *out of* $X$ deleted; see @fig-dag-underbar

::: {#fig-modified-dags layout-ncol=3}

```{tikz opts.label="tikz_settings"}
#| label: fig-dag-original
#| fig-cap: 'Original DAG, $G$'
#| echo: false
#| out-width: 100%

\begin{tikzpicture}[>={stealth}]
  \node (x) at (0,0) {X};
  \node (y) at (2,0) {Y};
  \node (z) at (1,1) {Z};
  \path[->] (z) edge (x);
  \path[->] (z) edge (y);
  \path[->] (x) edge (y);
\end{tikzpicture}
```

```{tikz opts.label="tikz_settings"}
#| label: fig-dag-overbar
#| fig-cap: '$G_{\overline{X}}$ with arrows *into* X removed'
#| echo: false
#| out-width: 100%

\definecolor{cutcolor}{HTML}{5d6174}

\begin{tikzpicture}[>={stealth}]
  \node (x) at (0,0) {X};
  \node (y) at (2,0) {Y};
  \node (z) at (1,1) {Z};
  \path[->, densely dotted, gray!40, thin] (z) edge (x);
  \draw[cutcolor, thick] (0.4,0.6) -- (0.6,0.4);
  \path[->] (z) edge (y);
  \path[->] (x) edge (y);
\end{tikzpicture}
```

```{tikz opts.label="tikz_settings"}
#| label: fig-dag-underbar
#| fig-cap: '$G_{\underline{X}}$ with arrows *out of* X removed'
#| echo: false
#| out-width: 100%

\definecolor{cutcolor}{HTML}{5d6174}

\begin{tikzpicture}[>={stealth}]
  \node (x) at (0,0) {X};
  \node (y) at (2,0) {Y};
  \node (z) at (1,1) {Z};
  \path[->] (z) edge (x);
  \path[->] (z) edge (y);
  \path[->, densely dotted, gray!40, thin] (x) edge (y);
  \draw[cutcolor, thick] (0.9,-0.1) -- (1.1,0.1);
\end{tikzpicture}
```

$G$, $G_{\overline{X}}$, and $G_{\underline{X}}$

:::

::: {.callout-tip}
#### Notation help!

I like to imagine this line notation as a wall:

- If the wall is on top of X like $\overline{X}$, you can't draw any arrows going into it, so you delete anything going in
- If the wall is on the bottom of X like $\underline{X}$, you can't draw any arrows going out of it, so you delete anything going out
:::


### The rules of *do*-calculus

Pearl's *do*-calculus provides three rules for eliminating $\operatorname{do}(\cdot)$ operators from causal expressions. Each rule works by checking for d-separation in either $G_{\overline{X}}$ or $G_{\underline{X}}$:

::: {#def-rule1}

#### Ignore an observation

We can ignore an extra observed variable $Z$ if it is d-separated from $Y$ in $G_{\overline{X}}$ (the graph with arrows into $X$ removed):

$$
P(y \mid \operatorname{do}(x), z) = P(y \mid \operatorname{do}(x)) \quad \text{if } (Y \perp Z \mid X)_{G_{\overline{X}}}
$$

:::

::: {#def-rule2}

#### Treat an intervention as an observation

We can replace $\operatorname{do}(x)$ with simply observing $x$ if, after removing X's outgoing edges, $X$ and $Y$ are d-separated given the covariates:

$$
P(y \mid \operatorname{do}(x), z) = P(y \mid x, z) \quad \text{if } (Y \perp X \mid Z)_{G_{\underline{X}}}
$$

:::

::: {#def-rule3}

#### Ignore an intervention

We can drop $\operatorname{do}(x)$ entirely if, after removing X's incoming edges, $X$ and $Y$ are d-separated given the covariates:

$$
P(y \mid \operatorname{do}(x), z) = P(y \mid z) \quad \text{if } (Y \perp X \mid Z)_{G_{\overline{X}}}
$$

:::

::: {#tip-flexible .callout-note}
#### These formulas are flexible

With all three of these rules, the variables names are interchangeable depending on the relationships in the DAG: $X$, $Y$, and $Z$ can stand for any sets of variables. Additionally, the conditioning set (the $z$ term) could be empty (e.g. $Z \rightarrow Y$ with no other nodes involved). 
:::


### Deriving the backdoor formula

With the rules of *do*-calculus, we can take our estimand of interest—the effect of $X$ on $Y$, or $P(y \mid \operatorname{do}(x))$—and transform it into a *do*-free statement that deals with the confounding from $Z$.

#### Step 1: Incorporate $Z$ into $P(y \mid \operatorname{do}(x))$

To adjust for the confounder $Z$, we need to incorporate it into the formula for our estimand. We do this by considering the joint distribution of $Y$ and $Z$ in a world where $X$ occurs through an intervention, or $P(y, z \mid \operatorname{do}(x))$. This gives us the probability that $Y = y$ and $Z = z$ simultaneously when we force $X = x$.

To get our target $P(y \mid \operatorname{do}(x))$ from this joint distribution, we marginalize over $Z$, or sum over all possible values of $Z$:

$$
{\color{blue} P(y \mid \operatorname{do}(x))} = \sum_z {\color{red} P(y, z \mid \operatorname{do}(x))}
$$ {#eq-marginalized}

Our estimand now includes $Z$, but this joint distribution equation is hard to work with. We need to break it smaller, more manageable pieces and separate $y$ and $x$. Using the chain rule of probability (which applies to interventional distributions just as it does to observational ones), we can expand out @eq-marginalized:

$$
{\color{red} P(y, z \mid \operatorname{do}(x))} = {\color{orange} P(y \mid \operatorname{do}(x), z) \times P(z \mid \operatorname{do}(x))}
$$ {#eq-expanded}

We can substitute that expanded version back into @eq-marginalized:

$$
{\color{blue} P(y \mid \operatorname{do}(x))} = \sum_z {\color{orange} P(y \mid \operatorname{do}(x), z) \times P(z \mid \operatorname{do}(x))}
$$ {#eq-marginalized-expanded}

Or without colors:

$$
P(y \mid \operatorname{do}(x)) = \sum_z P(y \mid \operatorname{do}(x), z) \times P(z \mid \operatorname{do}(x))
$$ {#eq-marginalized-expanded-final}

Now we have two $\operatorname{do}(\cdot)$-based quantities that we cannot directly estimate from data:

- $P(y \mid \operatorname{do}(x), z)$: "Given that we intervene on $X$ and observe $Z = z$, what's the probability of $Y = y$?"
- $P(z \mid \operatorname{do}(x))$: "In a world where we intervene on $X$, what's the probability that $Z = z$?"

Our next job is to use the rules of *do*-calculus to remove those $\operatorname{do}(\cdot)$ interventions.

#### Step 2: Applying Rule 2 to $P(y \mid \operatorname{do}(x), z)$

According to @def-rule2, we can replace an interventional $\operatorname{do}(x)$ with a regular observed $x$ if we meet specific conditions in $G_{\underline{X}}$, or the graph with all arrows out of $X$ deleted: $Y$ must be d-separated from $X$, given the covariates $Z$. Here's what $G_{\underline{X}}$ looks like: 

```{tikz opts.label="tikz_settings"}
#| label: fig-rule2-check
#| fig-cap: 'Check d-separation of $X$ and $Y$ given $Z$ in $G_{\underline{X}}$'
#| echo: false
#| out-width: 30%

\definecolor{cutcolor}{HTML}{5d6174}

\begin{tikzpicture}[>={stealth}]
  \node (x) at (0,0) {X};
  \node (y) at (2,0) {Y};
  \node (z) at (1,1) {Z};
  \path[->] (z) edge (x);
  \path[->] (z) edge (y);
  \path[->, densely dotted, gray!40, thin] (x) edge (y);
  \draw[cutcolor, thick] (0.9,-0.1) -- (1.1,0.1);
\end{tikzpicture}
```

The only path between $X$ and $Y$ in $G_{\underline{X}}$ is $X \leftarrow Z \rightarrow Y$. Adjusting for $Z$ blocks this path, so $(Y \perp X \mid Z)_{G_{\underline{X}}}$ holds. That means that we can swap out $\operatorname{do}(x)$ for a regular observed $x$:

$$
P(y \mid \operatorname{do}(x), z) = P(y \mid x, z)
$$

#### Step 3: Applying Rule 3 to $P(z \mid \operatorname{do}(x))$

According to @def-rule3, we can remove a $\operatorname{do}(\cdot)$ operator if we meet specific conditions in $G_{\overline{X}}$, or the graph with all arrows into $X$ deleted: $Z$ must be d-separated from $X$ in $G_{\overline{X}}$.

::: {.callout-note}
#### Wait, this doesn't exactly match Rule 3??

@def-rule3 officially talks about independence between $X$ and $Y$, but here we're talking about $X$ and $Z$. What gives?

Remember from @tip-flexible that these variable names are flexible. We don't have to look only at $X$ and $Y$—any nodes can stand in for those. In this case, we care about the relationship between $Z$ and $X$, where the "outcome" variable is $Z$ instead of $Y$. 

Additionally, *technically* @def-rule3 includes conditioning set $z$: $P(y \mid \operatorname{do}(x), z)$. However, the $z$ term in the formula can be empty. In this case, $Y$ is related to $X$ and $Z$ as a collider and, accordingly, we don't adjust for it, so we can leave it out of the equation. Thus, we can take this official expression from Rule 3:

$$
P(y \mid \operatorname{do}(x), z)
$$

and modify it by

- switching the "outcome" variable to $Z$, so $y$ becomes $z$, and
- using an empty conditioning set, so the "$z$" in $P(y \mid \operatorname{do}(x), z)$ disappears

…resulting in

$$
P(z \mid \operatorname{do}(x))
$$

for this special case.
:::

```{tikz opts.label="tikz_settings"}
#| label: fig-rule3-check
#| fig-cap: 'Check d-separation of $Z$ and $X$ in $G_{\overline{X}}$'
#| echo: false
#| out-width: 30%

\definecolor{cutcolor}{HTML}{5d6174}

\begin{tikzpicture}[>={stealth}]
  \node (x) at (0,0) {X};
  \node (y) at (2,0) {Y};
  \node (z) at (1,1) {Z};
  \path[->, densely dotted, gray!40, thin] (z) edge (x);
  \draw[cutcolor, thick] (0.4,0.6) -- (0.6,0.4);
  \path[->] (z) edge (y);
  \path[->] (x) edge (y);
\end{tikzpicture}
```

The only path between $Z$ and $X$ in $G_{\overline{X}}$ is $Z \rightarrow Y \leftarrow X$. In this case, $Y$ is a collider and since we don't adjust for or condition on colliders, that pathway is blocked and $(Z \perp X)_{G_{\overline{X}}}$ holds. That means that we can completely eliminate $\operatorname{do}(x)$:

$$
P(z \mid \operatorname{do}(x)) = P(z)
$$

#### Step 4: Final formula

Finally we can substitute both *do*-free results back into our original expression from @eq-marginalized-expanded-final:

$$
\begin{aligned}
P(y \mid \operatorname{do}(x)) &= \sum_z \underbrace{P(y \mid \operatorname{do}(x), z)}_{\text{Rule 2}} \times \underbrace{P(z \mid \operatorname{do}(x))}_{\text{Rule 3}} \\
&= \sum_z \underbrace{P(y \mid x, z)}_{\text{Rule 2}} \times \underbrace{P(z)}_{\text{Rule 3}}
\end{aligned}
$$

This gives us the official backdoor adjustment formula:

$$
\boxed{\rule{0pt}{1.5em}\;\; P(y \mid \operatorname{do}(x)) = \sum_z P(y \mid x, z) \times P(z) \;\;}
$$

All $\operatorname{do}(\cdot)$ operators are gone and every term on the right-hand side is an ordinary observational value. This means that we can estimate the causal effect of $X$ on $Y$ from observational data as long as we measure and adjust for $Z$.
